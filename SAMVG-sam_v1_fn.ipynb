{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_component_num = 100\n",
    "# max_bezier_curve_num = 1000\n",
    "\n",
    "# image_floder = 'CS 3570 Final Project Topic5'\n",
    "max_component_num = 20\n",
    "max_bezier_curve_num = 200\n",
    "\n",
    "image_floder = '128'\n",
    "\n",
    "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(model=sam,\n",
    "    points_per_side=32,\n",
    "    pred_iou_thresh=0.86,\n",
    "    stability_score_thresh=0.92,\n",
    "    crop_n_layers=1,\n",
    "    crop_n_points_downscale_factor=2,\n",
    "    min_mask_region_area=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import lstsq\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def compute_arc_length_params(points):\n",
    "    \"\"\"\n",
    "    計算弧長參數化的參數 t_i\n",
    "    :param points: 样本点列表 [(x0, y0), (x1, y1), ..., (xn, yn)]\n",
    "    :return: 弧长参数化后的参数列表 [t0, t1, ..., tn]\n",
    "    \"\"\"\n",
    "    n = len(points)\n",
    "    dists = [np.linalg.norm(np.array(points[i]) - np.array(points[i-1])) for i in range(1, n)]\n",
    "    s = [0] + np.cumsum(dists).tolist()\n",
    "    total_length = s[-1]\n",
    "    t = [si / total_length for si in s]\n",
    "    return t\n",
    "\n",
    "def fit_bezier_curve(points):\n",
    "    \"\"\"\n",
    "    拟合三次贝塞尔曲线\n",
    "    :param points: 样本点列表 [(x0, y0), (x1, y1), ..., (xn, yn)]\n",
    "    :return: 控制点 [(P0x, P0y), (P1x, P1y), (P2x, P2y), (P3x, P3y)]\n",
    "    \"\"\"\n",
    "    points = np.array(points)\n",
    "    t = compute_arc_length_params(points)\n",
    "    \n",
    "    # 设定 P0 和 P3\n",
    "    P0 = points[0]\n",
    "    P3 = points[-1]\n",
    "    \n",
    "    # 构建矩阵 A 和向量 B\n",
    "    A = []\n",
    "    Bx = []\n",
    "    By = []\n",
    "    \n",
    "    for i in range(1, len(points) - 1):\n",
    "        ti = t[i]\n",
    "        A.append([3 * (1 - ti)**2 * ti, 3 * (1 - ti) * ti**2])\n",
    "        Bx.append(points[i, 0] - ((1 - ti)**3 * P0[0] + ti**3 * P3[0]))\n",
    "        By.append(points[i, 1] - ((1 - ti)**3 * P0[1] + ti**3 * P3[1]))\n",
    "    \n",
    "    A = np.array(A)\n",
    "    Bx = np.array(Bx)\n",
    "    By = np.array(By)\n",
    "    \n",
    "    # 解最小二乘问题\n",
    "    Px, _, _, _ = lstsq(A, Bx)\n",
    "    Py, _, _, _ = lstsq(A, By)\n",
    "    \n",
    "    P1 = (Px[0], Py[0])\n",
    "    P2 = (Px[1], Py[1])\n",
    "    \n",
    "    return [tuple(P0), P1, P2, tuple(P3)],t\n",
    "\n",
    "def bezier_curve(t, p0, p1, p2, p3):\n",
    "    \"\"\"\n",
    "    计算贝塞尔曲线上的点\n",
    "    :param t: 参数t（0到1之间）\n",
    "    :param p0: 控制点P0\n",
    "    :param p1: 控制点P1\n",
    "    :param p2: 控制点P2\n",
    "    :param p3: 控制点P3\n",
    "    :return: 贝塞尔曲线上的点\n",
    "    \"\"\"\n",
    "    return (1-t)**3 * p0 + 3*(1-t)**2 * t * p1 + 3*(1-t) * t**2 * p2 + t**3 * p3\n",
    "\n",
    "def compute_approximation_error(points, control_points, points_t):\n",
    "    \"\"\"\n",
    "    计算逼近误差\n",
    "    :param points: 样本点列表 [(x0, y0), (x1, y1), ..., (xn, yn)]\n",
    "    :param control_points: 控制点列表 [(P0x, P0y), (P1x, P1y), (P2x, P2y), (P3x, P3y)]\n",
    "    :return: 逼近误差\n",
    "    \"\"\"\n",
    "    total_error = 0\n",
    "    n = len(points)\n",
    "    \n",
    "    # 遍历样本点\n",
    "    for point, t in zip(points,points_t):\n",
    "        curve_point = bezier_curve(t, *control_points)\n",
    "        dist = distance.euclidean(point, curve_point)\n",
    "        total_error +=dist\n",
    "    \n",
    "    return total_error\n",
    "\n",
    "def fit_bezier_curve_and_error(points):\n",
    "    control_points,points_t = fit_bezier_curve(points)\n",
    "    loss=compute_approximation_error(points,np.array(control_points),points_t)\n",
    "    return control_points,loss\n",
    "\n",
    "def mask_to_contours(mask):\n",
    "    mask = mask.astype(np.uint8)*255\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    contours_points = []\n",
    "    filled_masks_area = []\n",
    "    filled_masks = []\n",
    "    for contour in contours:\n",
    "        filled_mask = np.zeros(mask.shape, dtype=np.uint8)\n",
    "        cv2.drawContours(filled_mask, [contour], -1, (1), thickness=cv2.FILLED)\n",
    "        filled_masks.append(filled_mask)\n",
    "        filled_masks_area.append(np.sum(filled_mask))\n",
    "        contours_points.append(np.concatenate([contour[:, 0, :],contour[:1, 0, :]],0))\n",
    "    return contours_points,filled_masks,filled_masks_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_svg(filename,sorted_masks,scale):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write('<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"'+str(scale[3])+'\" height=\"'+str(scale[2])+'\" viewbox=\"0 0 '+str(scale[3])+' '+str(scale[2])+'\">\\n')\n",
    "        for ma in sorted_masks:\n",
    "            control_points_sets = ma[\"control_points_sets\"]\n",
    "            rgb = ma[\"color\"]\n",
    "            control_points = control_points_sets[0][\"control_points\"]\n",
    "            f.write('<path d=\"M {:.2f} {:.2f} '.format(control_points[0][0]*scale[1], control_points[0][1]*scale[0]))\n",
    "            for control_points_set in control_points_sets:\n",
    "                control_points = control_points_set[\"control_points\"]\n",
    "                f.write('C {:.2f} {:.2f}, {:.2f} {:.2f}, {:.2f} {:.2f} '.format(control_points[1][0]*scale[1], control_points[1][1]*scale[0],control_points[2][0]*scale[1], control_points[2][1]*scale[0], control_points[3][0]*scale[1],control_points[3][1]*scale[0]))\n",
    "            f.write('Z\" fill=\"rgb('+str(rgb[0])+','+str(rgb[1])+','+str(rgb[2])+')\" />\\n')\n",
    "        f.write('</svg>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SAMVGV1(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    scale = [1,1,image.shape[0],image.shape[1]]\n",
    "    if image.shape[0]*image.shape[1]>1024*1024:\n",
    "        scale = [image.shape[0]/1024,image.shape[1]/1024,image.shape[0],image.shape[1]]\n",
    "        image = cv2.resize(image, (1024, 1024))\n",
    "    masks = mask_generator.generate(image)\n",
    "    m=np.ones(image.shape[0:2])\n",
    "    contours_points,filled_masks,filled_masks_area=mask_to_contours(m)\n",
    "    ma = dict()\n",
    "    ma[\"contours_points\"] = contours_points[0]\n",
    "    ma[\"filled_mask\"] = filled_masks[0]\n",
    "    ma[\"filled_mask_area\"] = filled_masks_area[0]\n",
    "    new_masks=[ma]\n",
    "    for i in range(len(masks)):\n",
    "        m = masks[i]['segmentation']\n",
    "        contours_points,filled_masks,filled_masks_area=mask_to_contours(m)\n",
    "        for i in range(len(contours_points)):\n",
    "            ma = dict()\n",
    "            ma[\"contours_points\"] = contours_points[i]\n",
    "            ma[\"filled_mask\"] = filled_masks[i]\n",
    "            ma[\"filled_mask_area\"] = filled_masks_area[i]\n",
    "            if len(ma[\"contours_points\"])>=4:\n",
    "                new_masks.append(ma)\n",
    "    sorted_masks = sorted(new_masks, key=(lambda x: x['filled_mask_area']), reverse=True)[:max_component_num]\n",
    "    # 優化bezier_curve\n",
    "    use_bezier_curve_num = 0\n",
    "    for ma in sorted_masks:\n",
    "        control_points,loss=fit_bezier_curve_and_error(ma[\"contours_points\"])\n",
    "        control_points_set = dict()\n",
    "        control_points_set[\"control_points\"]=control_points\n",
    "        control_points_set[\"loss\"]=loss\n",
    "        control_points_set[\"range\"]=[0,len(ma[\"contours_points\"])-1]\n",
    "        ma[\"control_points_sets\"]=[control_points_set]\n",
    "        use_bezier_curve_num+=1\n",
    "        if use_bezier_curve_num>=max_bezier_curve_num:\n",
    "            break\n",
    "        \n",
    "    while use_bezier_curve_num<max_bezier_curve_num:\n",
    "        use_bezier_curve_num+=1\n",
    "        max_loss_control_points_set = sorted_masks[0][\"control_points_sets\"][0]\n",
    "        max_loss_ma_index = 0\n",
    "        max_loss_ma_control_points_sets_index = 0\n",
    "        for i1,ma in enumerate(sorted_masks):\n",
    "            for i2,control_points_set in enumerate(ma[\"control_points_sets\"]):\n",
    "                if control_points_set[\"loss\"]>max_loss_control_points_set[\"loss\"]:\n",
    "                    max_loss_control_points_set = control_points_set\n",
    "                    max_loss_ma_index = i1\n",
    "                    max_loss_ma_control_points_sets_index = i2\n",
    "        if max_loss_control_points_set[\"range\"][1]-max_loss_control_points_set[\"range\"][0]<8:\n",
    "            break\n",
    "        ma = sorted_masks[max_loss_ma_index]\n",
    "        sorted_masks[max_loss_ma_index][\"control_points_sets\"].pop(max_loss_ma_control_points_sets_index)\n",
    "        control_points_set = dict()\n",
    "        mt=int((max_loss_control_points_set[\"range\"][0]+max_loss_control_points_set[\"range\"][1])//2)\n",
    "        t1=max_loss_control_points_set[\"range\"][0]\n",
    "        t2=mt\n",
    "        control_points,loss=fit_bezier_curve_and_error(ma[\"contours_points\"][t1:t2])\n",
    "        control_points_set[\"control_points\"]=control_points\n",
    "        control_points_set[\"loss\"]=loss\n",
    "        control_points_set[\"range\"]=[t1,t2]\n",
    "        ma[\"control_points_sets\"].insert(max_loss_ma_control_points_sets_index,control_points_set)\n",
    "        control_points_set = dict()\n",
    "        t1=mt\n",
    "        t2=max_loss_control_points_set[\"range\"][1]\n",
    "        control_points,loss=fit_bezier_curve_and_error(ma[\"contours_points\"][t1:t2])\n",
    "        control_points_set[\"control_points\"]=control_points\n",
    "        control_points_set[\"loss\"]=loss\n",
    "        control_points_set[\"range\"]=[t1,t2]\n",
    "        ma[\"control_points_sets\"].insert(max_loss_ma_control_points_sets_index+1,control_points_set)\n",
    "    print(image_path+\":out \",use_bezier_curve_num)\n",
    "    # 決定顏色\n",
    "    sorted_masks.reverse()\n",
    "    image_color_mask = np.ones(sorted_masks[0][\"filled_mask\"].shape)\n",
    "    for i,ma in enumerate(sorted_masks):\n",
    "        tm = image_color_mask*ma[\"filled_mask\"]\n",
    "        sorted_masks[i][\"color\"] = np.sum(image * np.expand_dims(tm,2),(0,1))/np.sum(tm)\n",
    "        image_color_mask = image_color_mask * (1-ma[\"filled_mask\"])\n",
    "    sorted_masks.reverse()\n",
    "    write_svg('SVG_'+image_path.split('.')[0]+'.svg', sorted_masks,scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m random\u001b[38;5;241m.\u001b[39mshuffle(image_paths)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m image_paths:\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mSAMVGV1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[23], line 8\u001b[0m, in \u001b[0;36mSAMVGV1\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m     scale \u001b[38;5;241m=\u001b[39m [image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1024\u001b[39m,image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1024\u001b[39m,image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m      7\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(image, (\u001b[38;5;241m1024\u001b[39m, \u001b[38;5;241m1024\u001b[39m))\n\u001b[1;32m----> 8\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[43mmask_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m m\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mones(image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m     10\u001b[0m contours_points,filled_masks,filled_masks_area\u001b[38;5;241m=\u001b[39mmask_to_contours(m)\n",
      "File \u001b[1;32mc:\\Users\\a5658\\anaconda3\\envs\\SAMVG\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a5658\\anaconda3\\envs\\SAMVG\\lib\\site-packages\\segment_anything\\automatic_mask_generator.py:163\u001b[0m, in \u001b[0;36mSamAutomaticMaskGenerator.generate\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03mGenerates masks for the given image.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03m         the mask, given in XYWH format.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# Generate masks\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m mask_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# Filter small disconnected regions and holes in masks\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_mask_region_area \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\a5658\\anaconda3\\envs\\SAMVG\\lib\\site-packages\\segment_anything\\automatic_mask_generator.py:206\u001b[0m, in \u001b[0;36mSamAutomaticMaskGenerator._generate_masks\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    204\u001b[0m data \u001b[38;5;241m=\u001b[39m MaskData()\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m crop_box, layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(crop_boxes, layer_idxs):\n\u001b[1;32m--> 206\u001b[0m     crop_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_crop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_box\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m     data\u001b[38;5;241m.\u001b[39mcat(crop_data)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# Remove duplicate masks between crops\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\a5658\\anaconda3\\envs\\SAMVG\\lib\\site-packages\\segment_anything\\automatic_mask_generator.py:236\u001b[0m, in \u001b[0;36mSamAutomaticMaskGenerator._process_crop\u001b[1;34m(self, image, crop_box, crop_layer_idx, orig_size)\u001b[0m\n\u001b[0;32m    234\u001b[0m cropped_im \u001b[38;5;241m=\u001b[39m image[y0:y1, x0:x1, :]\n\u001b[0;32m    235\u001b[0m cropped_im_size \u001b[38;5;241m=\u001b[39m cropped_im\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m--> 236\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcropped_im\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# Get points for this crop\u001b[39;00m\n\u001b[0;32m    239\u001b[0m points_scale \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(cropped_im_size)[\u001b[38;5;28;01mNone\u001b[39;00m, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\a5658\\anaconda3\\envs\\SAMVG\\lib\\site-packages\\segment_anything\\predictor.py:60\u001b[0m, in \u001b[0;36mSamPredictor.set_image\u001b[1;34m(self, image, image_format)\u001b[0m\n\u001b[0;32m     57\u001b[0m input_image_torch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(input_image, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     58\u001b[0m input_image_torch \u001b[38;5;241m=\u001b[39m input_image_torch\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()[\u001b[38;5;28;01mNone\u001b[39;00m, :, :, :]\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_torch_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image_torch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a5658\\anaconda3\\envs\\SAMVG\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\a5658\\anaconda3\\envs\\SAMVG\\lib\\site-packages\\segment_anything\\predictor.py:89\u001b[0m, in \u001b[0;36mSamPredictor.set_torch_image\u001b[1;34m(self, transformed_image, original_image_size)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(transformed_image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:])\n\u001b[0;32m     88\u001b[0m input_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpreprocess(transformed_image)\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_image_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\a5658\\anaconda3\\envs\\SAMVG\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\a5658\\anaconda3\\envs\\SAMVG\\lib\\site-packages\\segment_anything\\modeling\\image_encoder.py:112\u001b[0m, in \u001b[0;36mImageEncoderViT.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    109\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embed\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m--> 112\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneck(x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\a5658\\anaconda3\\envs\\SAMVG\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\a5658\\anaconda3\\envs\\SAMVG\\lib\\site-packages\\segment_anything\\modeling\\image_encoder.py:174\u001b[0m, in \u001b[0;36mBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    171\u001b[0m     H, W \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    172\u001b[0m     x, pad_hw \u001b[38;5;241m=\u001b[39m window_partition(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size)\n\u001b[1;32m--> 174\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# Reverse window partition\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\a5658\\anaconda3\\envs\\SAMVG\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\a5658\\anaconda3\\envs\\SAMVG\\lib\\site-packages\\segment_anything\\modeling\\image_encoder.py:234\u001b[0m, in \u001b[0;36mAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    231\u001b[0m attn \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale) \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_rel_pos:\n\u001b[1;32m--> 234\u001b[0m     attn \u001b[38;5;241m=\u001b[39m \u001b[43madd_decomposed_rel_pos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrel_pos_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrel_pos_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m attn \u001b[38;5;241m=\u001b[39m attn\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    237\u001b[0m x \u001b[38;5;241m=\u001b[39m (attn \u001b[38;5;241m@\u001b[39m v)\u001b[38;5;241m.\u001b[39mview(B, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, H, W, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(B, H, W, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\a5658\\anaconda3\\envs\\SAMVG\\lib\\site-packages\\segment_anything\\modeling\\image_encoder.py:349\u001b[0m, in \u001b[0;36madd_decomposed_rel_pos\u001b[1;34m(attn, q, rel_pos_h, rel_pos_w, q_size, k_size)\u001b[0m\n\u001b[0;32m    347\u001b[0m q_h, q_w \u001b[38;5;241m=\u001b[39m q_size\n\u001b[0;32m    348\u001b[0m k_h, k_w \u001b[38;5;241m=\u001b[39m k_size\n\u001b[1;32m--> 349\u001b[0m Rh \u001b[38;5;241m=\u001b[39m \u001b[43mget_rel_pos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_pos_h\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m Rw \u001b[38;5;241m=\u001b[39m get_rel_pos(q_w, k_w, rel_pos_w)\n\u001b[0;32m    352\u001b[0m B, _, dim \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\a5658\\anaconda3\\envs\\SAMVG\\lib\\site-packages\\segment_anything\\modeling\\image_encoder.py:322\u001b[0m, in \u001b[0;36mget_rel_pos\u001b[1;34m(q_size, k_size, rel_pos)\u001b[0m\n\u001b[0;32m    319\u001b[0m k_coords \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(k_size)[\u001b[38;5;28;01mNone\u001b[39;00m, :] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mmax\u001b[39m(q_size \u001b[38;5;241m/\u001b[39m k_size, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m    320\u001b[0m relative_coords \u001b[38;5;241m=\u001b[39m (q_coords \u001b[38;5;241m-\u001b[39m k_coords) \u001b[38;5;241m+\u001b[39m (k_size \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mmax\u001b[39m(q_size \u001b[38;5;241m/\u001b[39m k_size, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m--> 322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrel_pos_resized\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrelative_coords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import random\n",
    "image_paths=glob.glob(image_floder+\"/*.jpg\")+glob.glob(image_floder+\"/*.png\")\n",
    "random.shuffle(image_paths)\n",
    "for image_path in image_paths:\n",
    "    SAMVGV1(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAMVG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
